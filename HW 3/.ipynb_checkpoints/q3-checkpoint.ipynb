{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "beeee8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "School: University of California, Berkeley\n",
    "Course: BIOENG 145/245\n",
    "Author: Yorick Chern\n",
    "Instructor: Liana Lareau\n",
    "Assignment 3\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3a2ae1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Q:  read the data from the q3_data.csv.\n",
    "        the data contains 2 columns with 1 column being the sequence and the second column being\n",
    "        either 1 or 0. Then, shuffle the data and create a training and testing set based on test_size.\n",
    "\n",
    "        To read the data, I recommend using pandas' pd.read_csv() function.\n",
    "        To shuffle and split the data into training/testing sets, I recommend sklearn's train_test_split\n",
    "\n",
    "        You can use any methods you want to read in the dataset as long as you produce the correct\n",
    "        output.\n",
    "\n",
    "        Note, in the case that we are reading q3_data.csv, there should be 5000 sequences.\n",
    "\n",
    "    Inputs\n",
    "    - file_name: a string, the name of the data file (\"q3_data.csv\")\n",
    "    - test_size: a float to show how many\n",
    "\n",
    "    Outputs\n",
    "    - X_train: np.array with shape (N * (1 - test_size)); each item is a sequence from the dataset\n",
    "    - X_test: np.array with shape (N * test_size)\n",
    "    - y_train: np.array with shape (N * (1 - test_size)); y[i] is X[i]'s ground-truth label\n",
    "    - y_test: np.array with shape (N * test_size)\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: use your favorite methods to complete this section - no restriction (do not import any foreign packages, but train_test_split is ok)\n",
    "    file = pd.read_csv(file_name, header=None, sep='\\s+')\n",
    "    X = file[0].values\n",
    "    y = file[1].values\n",
    "    # split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=True)\n",
    "\n",
    "    assert type(X_train) == type(X_test) == type(y_train) == type(y_test) == np.ndarray, f\"read_data() NEEDS to output np.ndarray, instead it's {type(X_train)}!\"\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "    assert type(X_train) == type(X_test) == type(y_train) == type(y_test) == np.ndarray, f\"read_data() NEEDS to output np.ndarray, instead it's {type(X_train)}!\"\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "478cd8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('q3_data.csv', header=None, sep='\\s+')\n",
    "data[0].values\n",
    "data[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4fc4a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transition_matrix(data, k):\n",
    "    \"\"\"\n",
    "    Q:  Here, we will build a transition matrix for a set of sequences.\n",
    "        Suppose we have a sequence \"ACTAGCTACT...\" and k = 3, then the \n",
    "        list of states for this sequence will be:\n",
    "        ex: states = [ACT, CTA, TAC, ACT,...]. \n",
    "        \n",
    "        In order to make it easier for ourselves, we will create a dictionary\n",
    "        mapping every kmer state to an integer label. So, if our\n",
    "        kmer2idx dictionary is {'ACT' : 0, 'CTA' : 1, 'TAC' : 2, ...}\n",
    "        then the states above can be written as [0, 1, 2, 1 ..]\n",
    "        \n",
    "        Next, we build a 2D transition matrix where\n",
    "        trans_prob[i, j] = probability of state i transitioning to state j.\n",
    "        ex: trans_prob[3, 1] = probability of state 3 to state 1. \n",
    "\n",
    "        How do we get this number? Say we want to find trans_prob[1, 2], which is the transition probability\n",
    "        of 'CTA' to 'TAC'. We count how many transitions from 'CTA' to 'TAC' there are and divide\n",
    "        this number by the TOTAL number of transitions in the entire dataset, and this gives us\n",
    "        Pr['CTA' | 'TAC']. However, notice that 'CTA' to 'TAC' in reality is just 'CTAC', we can also consider rewrite this\n",
    "        as Pr['C' | 'CTA']. Then, we define our transition matrix as a (64, 64) matrix where each row is a possible 3-mer\n",
    "        and each of the 4 columns is A, G, T, or C. Then, we realize that:\n",
    "        Pr['A' | 'CTA'] + Pr['T' | 'CTA'] + Pr['G' | 'CTA'] + Pr['C' | 'CTA'] = 1\n",
    "\n",
    "    Inputs\n",
    "    - data: np.array with shape (training size); each item is a sequence from the dataset\n",
    "    - kmer: an int describing the kmer we are interested in\n",
    "\n",
    "    Outputs\n",
    "    - kmer2idx: a dictionary that gives us the index of each kmer (ex: kmer2idx['ATC'] = 2 and\n",
    "                kmer2idx['TCG'] = 4, then trans_mat[2][4] is the probability of \"ATCG\" happening, \n",
    "                given that we started with \"ATC\")\n",
    "                this is important as it helps us understand what the transition matrix (trans_probs)\n",
    "                means.\n",
    "    - trans_probs: np.array with shape (# of states, # of states) with the properties described above\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Initialize transition probability matrix & generate all possible kmers\n",
    "    trans_prob = np.zeros((4**k, 4))\n",
    "    kmers = [''.join(p) for p in product(*[['A', 'G', 'T', 'C']] * k)]    # generate a list of all possible kmers combinations, use itertools.product() - read the docs\n",
    "    # build a dictionary to map each kmer to an integer, this will allow us to keep track of where each kmer\n",
    "    # is located in the transition matrix (trans_prob)\n",
    "    \n",
    "    kmer2idx = {}\n",
    "    for i in range (np.power(4, k)): #no hard code\n",
    "        kmer2idx[kmers[i]] = i   # kmer2idx['ATC'] = 4, for example\n",
    "    nt2idx = {'A': 0, 'G': 1, 'T': 2, 'C': 3}   # do not modify this\n",
    "    \n",
    "    # Iterate through the data to count each transition\n",
    "    \n",
    "    for seq in data:\n",
    "        for position, nt in enumerate(seq):\n",
    "            if position < len(seq) - k:            \n",
    "                thisKmer = seq[position:position+k]\n",
    "                thisIndex = kmer2idx[thisKmer]\n",
    "                nextIndex = nt2idx[seq[position+k]]\n",
    "                trans_prob[thisIndex][nextIndex] += 1\n",
    "            \n",
    "    trans_prob = np.add(trans_prob, 1) # apply 1 pseudocount\n",
    "\n",
    "    # Normalize transition matrix\n",
    "    trans_prob =  trans_prob / trans_prob.sum(axis=1, keepdims=True)\n",
    "\n",
    "    return kmer2idx, trans_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9545e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_odds_ratio(seq, k, pos_kmer2idx, pos_trans_probs, neg_kmer2idx, neg_trans_probs):\n",
    "    \"\"\"\n",
    "    Q:  this function will calculate the log odds ratio of a sequence with the following formula\n",
    "\n",
    "    log_odds = log(probability of being class 1 / probability of being class 0)\n",
    "\n",
    "    Inputs\n",
    "    - seq: a string, the sequence to be classified\n",
    "    - k: an int, the kmer substring length\n",
    "    - pos_kmer2idx: the index system dictionary for the positive (class 1) transition matrix\n",
    "    - pos_trans_probs: the transition matrix for the positive sequences (class 1 sequences)\n",
    "    - neg_kmer2idx: same logic as pos_kmer2idx but for the negative sequences (class 0 sequences)\n",
    "    - neg_trans_probs: same logic as neg_trans_probs but for the negative sequences (class 0 sequences)\n",
    "\n",
    "    Outputs\n",
    "    - score: a float, the log odds ratio\n",
    "    \"\"\"\n",
    "    nt2idx = {'A': 0, 'G': 1, 'T': 2, 'C': 3}\n",
    "    score = 0\n",
    "    pos_prob = 0\n",
    "    neg_prob = 0\n",
    "    for i in range(len(seq)):\n",
    "        # calculate the log odds ratio using the variables passed\n",
    "        if i < len(seq) - k:\n",
    "            thisKmer = seq[i:i+k]\n",
    "            thisPosIndex = pos_kmer2idx[thisKmer]\n",
    "            thisNegIndex = neg_kmer2idx[thisKmer]\n",
    "            nextIndex = nt2idx[seq[i+k]]\n",
    "            # pos_prob = pos_prob * pos_trans_probs[thisPosIndex][nextIndex]\n",
    "            # neg_prob = neg_prob * neg_trans_probs[thisNegIndex][nextIndex]\n",
    "            pos_prob += np.log(pos_trans_probs[thisPosIndex][nextIndex])\n",
    "            neg_prob += np.log(neg_trans_probs[thisNegIndex][nextIndex])\n",
    "\n",
    "    score = pos_prob - neg_prob\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a5d4b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(seq, k, pos_kmer2idx, pos_trans_probs, neg_kmer2idx, neg_trans_probs):\n",
    "    \"\"\"\n",
    "    Q:  takes a sequence and classifies whether the sequence is a positive class or a negative class.\n",
    "        if log_odds_ratio > 0, (probability of positive > negative) ==> classify as positive class!\n",
    "        else if log_odds_ratio < 0 ==> classify as negative class!\n",
    "\n",
    "    Inputs:\n",
    "    (check the function above, they have the same specs)\n",
    "\n",
    "    Outputs:\n",
    "    - returns an integer, 0 or 1\n",
    "    \"\"\"\n",
    "\n",
    "    if log_odds_ratio(seq, k, pos_kmer2idx, pos_trans_probs, neg_kmer2idx, neg_trans_probs) > 0:\n",
    "        return 1\n",
    "    elif log_odds_ratio(seq, k, pos_kmer2idx, pos_trans_probs, neg_kmer2idx, neg_trans_probs) < 0:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "88bb18d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Markov Chain with k = 1\n",
      "Building positive transition matrix...\n",
      "Building negative transition matrix...\n",
      "Classifying testing dataset...\n",
      "Testing Accuracy: 0.88\n",
      "Fetching autograder validation data...\n",
      "Classifying autograder data...\n",
      "Loading predictions to q3_predictions.npy...\n",
      "\n",
      "\n",
      "Running Markov Chain with k = 2\n",
      "Building positive transition matrix...\n",
      "Building negative transition matrix...\n",
      "Classifying testing dataset...\n",
      "Testing Accuracy: 0.982\n",
      "Fetching autograder validation data...\n",
      "Classifying autograder data...\n",
      "Loading predictions to q3_predictions.npy...\n",
      "\n",
      "\n",
      "Running Markov Chain with k = 3\n",
      "Building positive transition matrix...\n",
      "Building negative transition matrix...\n",
      "Classifying testing dataset...\n",
      "Testing Accuracy: 0.989\n",
      "Fetching autograder validation data...\n",
      "Classifying autograder data...\n",
      "Loading predictions to q3_predictions.npy...\n",
      "\n",
      "\n",
      "Running Markov Chain with k = 4\n",
      "Building positive transition matrix...\n",
      "Building negative transition matrix...\n",
      "Classifying testing dataset...\n",
      "Testing Accuracy: 0.991\n",
      "Fetching autograder validation data...\n",
      "Classifying autograder data...\n",
      "Loading predictions to q3_predictions.npy...\n",
      "\n",
      "\n",
      "Running Markov Chain with k = 5\n",
      "Building positive transition matrix...\n",
      "Building negative transition matrix...\n",
      "Classifying testing dataset...\n",
      "Testing Accuracy: 0.988\n",
      "Fetching autograder validation data...\n",
      "Classifying autograder data...\n",
      "Loading predictions to q3_predictions.npy...\n",
      "\n",
      "Markov Chain Assignment Complete!\n",
      "\n",
      "===== SUBMISSION INSTRUCTIONS! =====\n",
      "Don't forget to submit all the q3_predictions_k=*.npy along with your q1.py, q2.py, and q3.py!\n",
      "WEHN SUBMITTING TO GRADESCOPE, PLEASE DO NOT INCLUDE THE .csv files!!!\n",
      "DO NOT CHANGE ANY FILE NAMES, OR ELSE THE AUTOGRADER WILL NOT BE ABLE TO FIND YOUR FILE!!\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS\n",
    "def main(k):\n",
    "    \"\"\"\n",
    "    To make your things smoother, I included this function to help you debug and test your code out.\n",
    "    Unless you are 100% sure with what you're doing, try not to alter any code from this section.\n",
    "    This code should split the dataset, train the Markov Chain on the training set, test the MC\n",
    "    on the testing set, and generate predictions of q3_validation_data.csv that you will upload to\n",
    "    Gradescope for autograding. If your test set achieves an accuracy of 0.97+, you should be good\n",
    "    to submit your predictions to the autograder.\n",
    "\n",
    "    Note: You do not have the ground truth labels for q3_validation_data.csv.\n",
    "    \"\"\"\n",
    "    print(\"\\nRunning Markov Chain with k = {}\".format(k))\n",
    "    # split the dataset\n",
    "    X_train, X_test, y_train, y_test = read_data(\"q3_data.csv\")\n",
    "\n",
    "    # find positive classes (class 1) and build the transition matrix\n",
    "    print(\"Building positive transition matrix...\")\n",
    "    positive_idx = np.where(y_train == 1)[0]\n",
    "    pos_kmer2idx, pos_trans_mat = build_transition_matrix(X_train[positive_idx], k)\n",
    "    assert np.abs(np.mean(np.sum(pos_trans_mat, axis=1)) - 1.0) < 1e-3, f\"Positive transition matrix needs to have every row sum to 1! Instead it's {np.mean(np.sum(pos_trans_mat, axis=1))}\"\n",
    "\n",
    "    # find negative classes (class 0) and build the transition matrix\n",
    "    print(\"Building negative transition matrix...\")\n",
    "    negative_idx = np.where(y_train == 0)[0]\n",
    "    neg_kmer2idx, neg_trans_mat = build_transition_matrix(X_train[negative_idx], k)\n",
    "    assert np.abs(np.mean(np.sum(neg_trans_mat, axis=1)) - 1.0) < 1e-5, f\"Negative transition matrix needs to have every row sum to 1! Instead it's {np.mean(np.sum(neg_trans_mat, axis=1))}\"\n",
    "\n",
    "    print(\"Classifying testing dataset...\")\n",
    "    y_pred = np.zeros_like(y_test)\n",
    "    for i in range(X_test.shape[0]):\n",
    "        seq = X_test[i]\n",
    "        y_pred[i] = classify(seq, k, pos_kmer2idx, pos_trans_mat, neg_kmer2idx, neg_trans_mat)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Testing Accuracy: {}\".format(accuracy))\n",
    "    acc = [None, 0.85, 0.98, 0.98, 0.96, 0.93]\n",
    "    if accuracy < acc[k]:\n",
    "        print(\"(note: you need an accuracy of at least {} for k = {} in order to pass the autograder!\".format(acc[k], k))\n",
    "\n",
    "    # classify hidden dataset for autograder\n",
    "    # loading predictions to q3_predictions.npy\n",
    "    print(\"Fetching autograder validation data...\")\n",
    "    test_data = pd.read_csv(\"q3_validation_data.csv\", sep=' ', header=None)\n",
    "    test_data = test_data.to_numpy().squeeze()\n",
    "\n",
    "    print(\"Classifying autograder data...\")\n",
    "    pred = np.zeros(test_data.shape[0])\n",
    "    for i in range(test_data.shape[0]):\n",
    "        seq = test_data[i]\n",
    "        pred[i] = classify(seq, k, pos_kmer2idx, pos_trans_mat, neg_kmer2idx, neg_trans_mat)\n",
    "    \n",
    "    print(\"Loading predictions to q3_predictions.npy...\\n\")\n",
    "    np.save(\"q3_predictions_k={}\".format(k), pred)\n",
    "\n",
    "    \"\"\"----- Instructor Version ----- (DO NOT INCLUDE IN THE HW)\"\"\"\n",
    "    # test_label = np.load(\"q3_val_labels.npy\")\n",
    "    # accuracy = accuracy_score(test_label, pred)\n",
    "    # print(\"Autograder Accuracy: {}\".format(accuracy))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for k in range(1, 6):\n",
    "        main(k)\n",
    "    \n",
    "    print(\"Markov Chain Assignment Complete!\")\n",
    "\n",
    "    print(\"\\n===== SUBMISSION INSTRUCTIONS! =====\")\n",
    "    print(\"Don't forget to submit all the q3_predictions_k=*.npy along with your q1.py, q2.py, and q3.py!\")\n",
    "    print(\"WEHN SUBMITTING TO GRADESCOPE, PLEASE DO NOT INCLUDE THE .csv files!!!\")\n",
    "    print(\"DO NOT CHANGE ANY FILE NAMES, OR ELSE THE AUTOGRADER WILL NOT BE ABLE TO FIND YOUR FILE!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d2a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a05612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194fe282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
